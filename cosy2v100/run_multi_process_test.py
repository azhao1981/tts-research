#!/usr/bin/env python3
"""
å¤šè¿›ç¨‹æµ‹è¯•å¯åŠ¨å™¨
æ”¯æŒå¤šè¿›ç¨‹å¹¶å‘æµ‹è¯•ï¼Œæ¯ä¸ªè¿›ç¨‹å¯ä»¥è¿è¡Œå¤šä¸ªæ‰¹æ¬¡
"""

import argparse
import multiprocessing as mp
import subprocess
import sys
from pathlib import Path
from typing import List
import time
import json


def run_process(process_id: int, args: List[str]):
    """è¿è¡Œå•ä¸ªè¿›ç¨‹"""
    try:
        # æ·»åŠ è¿›ç¨‹ ID åˆ°è¾“å‡ºç›®å½•
        output_dir = Path(args.output) / f"process_{process_id}"
        output_dir.mkdir(parents=True, exist_ok=True)

        # æ„å»ºè¿›ç¨‹ç‰¹å®šçš„å‚æ•°
        cmd = [
            sys.executable,
            "multi_process_test.py",
            "--url", args.url,
            "--audio", args.audio,
            "--text", args.text,
            "--prompt-text", args.prompt_text,
            "--concurrency", str(args.concurrency),
            "--batches", str(args.batches),
            "--output", str(output_dir),
        ]

        if args.no_save_wav:
            cmd.append("--no-save-wav")

        # è¿è¡Œå­è¿›ç¨‹
        result = subprocess.run(cmd, capture_output=True, text=True)

        # è¾“å‡ºç»“æœ
        if result.stdout:
            print(f"\n[è¿›ç¨‹ {process_id} è¾“å‡º]:")
            print(result.stdout)
        if result.stderr:
            print(f"\n[è¿›ç¨‹ {process_id} é”™è¯¯]:")
            print(result.stderr)

        return result.returncode

    except Exception as e:
        print(f"è¿›ç¨‹ {process_id} å‡ºé”™: {e}")
        return 1


def merge_results(output_dir: Path, process_count: int):
    """åˆå¹¶æ‰€æœ‰è¿›ç¨‹çš„ç»“æœ"""
    print("\nğŸ“Š åˆå¹¶æ‰€æœ‰è¿›ç¨‹çš„ç»“æœ...")

    all_results = []
    success_count = 0
    failure_count = 0
    total_tasks = 0

    # éå†æ‰€æœ‰è¿›ç¨‹ç›®å½•
    for pid in range(process_count):
        process_dir = output_dir / f"process_{pid + 1}"
        if not process_dir.exists():
            continue

        # æŸ¥æ‰¾æ‰€æœ‰ç»“æœæ–‡ä»¶
        for result_file in process_dir.glob("*_results.json"):
            try:
                with open(result_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                    # æ”¶é›†ç»“æœ
                    all_results.extend(data.get('results', []))

                    # ç»Ÿè®¡ä¿¡æ¯
                    batch_info = data.get('batch_info', {})
                    success_count += batch_info.get('success_count', 0)
                    failure_count += batch_info.get('failure_count', 0)
                    total_tasks += batch_info.get('total_tasks', 0)

            except Exception as e:
                print(f"  è­¦å‘Šï¼šæ— æ³•è¯»å– {result_file}: {e}")

    # ä¿å­˜åˆå¹¶åçš„ç»“æœ
    if all_results:
        merged_file = output_dir / f"merged_results_{int(time.time())}.json"
        merged_data = {
            "summary": {
                "total_processes": process_count,
                "total_tasks": total_tasks,
                "total_success": success_count,
                "total_failure": failure_count,
                "success_rate": (success_count / total_tasks * 100) if total_tasks > 0 else 0,
            },
            "results": all_results
        }

        with open(merged_file, 'w', encoding='utf-8') as f:
            json.dump(merged_data, f, indent=2, ensure_ascii=False)

        print(f"âœ… åˆå¹¶ç»“æœå·²ä¿å­˜åˆ°: {merged_file}")
        print(f"\nğŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
        print(f"  æ€»è¿›ç¨‹æ•°: {process_count}")
        print(f"  æ€»ä»»åŠ¡æ•°: {total_tasks}")
        print(f"  æˆåŠŸæ•°: {success_count}")
        print(f"  å¤±è´¥æ•°: {failure_count}")
        print(f"  æˆåŠŸç‡: {merged_data['summary']['success_rate']:.1f}%")

        # è®¡ç®—å¹³å‡å€¼
        if success_count > 0:
            success_results = [r for r in all_results if r.get('success', False)]
            avg_ttfb = sum(r.get('ttfb_ms', 0) for r in success_results) / len(success_results)
            avg_rtf = sum(r.get('rtf', 0) for r in success_results) / len(success_results)
            print(f"  å¹³å‡ TTFB: {avg_ttfb:.0f} ms")
            print(f"  å¹³å‡ RTF: {avg_rtf:.3f}")


def main():
    parser = argparse.ArgumentParser(description="å¤šè¿›ç¨‹ TTS å‹æµ‹å¯åŠ¨å™¨")
    parser.add_argument("--url", default="http://127.0.0.1:13099/stream",
                       help="TTS æœåŠ¡åœ°å€")
    parser.add_argument("--audio", required=True,
                       help="å‚è€ƒéŸ³é¢‘æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--text",
                       default="å–‚ï¼Œæå…ˆç”Ÿæ‚¨å¥½ï¼Œæˆ‘è¿™è¾¹æ˜¯å…ˆé”‹æ•™è‚²çš„ç‹è€å¸ˆã€‚æ‰“ç”µè¯æ˜¯æƒ³è·Ÿæ‚¨åŒæ­¥ä¸€ä¸ªå¯¹æ‚¨å®¶å­©å­å¯èƒ½æœ‰ç”¨çš„ä¿¡æ¯ã€‚",
                       help="ç›®æ ‡æ–‡æœ¬")
    parser.add_argument("--prompt-text",
                       default="å’±ä»¬è¿™ä¸ªé¡¹ç›®å‘¢å±äºæ˜¯æŠ•å…¥ä½ï¼Œå›æœ¬å¿«ï¼Œè€Œä¸”ç°åœ¨åŠ ç›Ÿå‘¢è¿˜æœ‰ä¸€äº›æ”¿ç­–ä¸Šçš„è¿™ä¸ªä¼˜æƒ ï¼Œå‘ƒï¼Œæ‚¨çœ‹æˆ‘åç»­è®©æ‹›å•†ç»ç†è”ç³»æ‚¨ï¼Œç»™æ‚¨è¯¦ç»†ä»‹ç»ä¸€ä¸‹å¯ä»¥å—ï¼Ÿå‘ƒï¼Œä¸ä¼šå ç”¨æ‚¨å¤ªå¤šæ—¶é—´çš„ï¼Œä¹Ÿæ˜¯ç»™æ‚¨è‡ªå·±ä¸€ä¸ªèµšé’±çš„æœºä¼šå˜›ã€‚",
                       help="æç¤ºæ–‡æœ¬")
    parser.add_argument("--concurrency", type=int, default=1,
                       help="æ¯ä¸ªè¿›ç¨‹çš„å¹¶å‘æ•°")
    parser.add_argument("--batches", type=int, default=1,
                       help="æ¯ä¸ªè¿›ç¨‹çš„æ‰¹æ¬¡æ•°")
    parser.add_argument("--processes", type=int, default=2,
                       help="è¿›ç¨‹æ•°")
    parser.add_argument("--output", default="./test_output",
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--no-save-wav", action="store_true",
                       help="ä¸ä¿å­˜ WAV æ–‡ä»¶")

    args = parser.parse_args()

    # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶
    audio_file = Path(args.audio)
    if not audio_file.exists():
        print(f"âŒ éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
        return

    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    print(f"ğŸš€ å¯åŠ¨å¤šè¿›ç¨‹å‹æµ‹")
    print(f"  URL: {args.url}")
    print(f"  éŸ³é¢‘: {audio_file}")
    print(f"  è¿›ç¨‹æ•°: {args.processes}")
    print(f"  æ¯è¿›ç¨‹å¹¶å‘æ•°: {args.concurrency}")
    print(f"  æ¯è¿›ç¨‹æ‰¹æ¬¡æ•°: {args.batches}")
    print(f"  æ€»è¯·æ±‚æ•°: {args.processes * args.concurrency * args.batches}")
    print(f"  è¾“å‡ºç›®å½•: {output_dir}")
    print(f"  ä¿å­˜ WAV: {'å¦' if args.no_save_wav else 'æ˜¯'}")

    # åˆ›å»ºè¿›ç¨‹æ± 
    start_time = time.time()

    print(f"\nâ° å¯åŠ¨ {args.processes} ä¸ªè¿›ç¨‹...")
    processes = []

    # å¯åŠ¨æ‰€æœ‰è¿›ç¨‹
    for pid in range(args.processes):
        p = mp.Process(target=run_process, args=(pid + 1, args))
        p.start()
        processes.append(p)
        print(f"  è¿›ç¨‹ {pid + 1} å·²å¯åŠ¨ (PID: {p.pid})")

    # ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ
    print(f"\nâ³ ç­‰å¾…æ‰€æœ‰è¿›ç¨‹å®Œæˆ...")
    for p in processes:
        p.join()

    # è®¡ç®—æ€»è€—æ—¶
    total_time = time.time() - start_time
    print(f"\nâœ… æ‰€æœ‰è¿›ç¨‹å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f} ç§’")

    # åˆå¹¶ç»“æœ
    merge_results(output_dir, args.processes)


if __name__ == "__main__":
    # Windows ä¸‹å¤šè¿›ç¨‹ä¿æŠ¤
    mp.freeze_support()
    main()